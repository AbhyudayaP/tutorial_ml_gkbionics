% rubber: module xelatex
\documentclass[english,final,compress]{beamer}
%\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\mode<beamer>{\usetheme{Bonn}}
\usepackage{fontspec}
\defaultfontfeatures{Mapping=tex-text}
\usepackage{xunicode}
\usepackage{xltxtra}
\setmainfont[Scale=0.86,Mapping=tex-text]{News Gothic MT}
\setsansfont[Scale=0.86,Mapping=tex-text]{News Gothic MT}
\setmonofont[Scale=0.86,Mapping=tex-text]{Andale Mono}
\usepackage{polyglossia}
\setdefaultlanguage{english}
\usepackage[EU1]{fontenc}
\usepackage{listings}
\usepackage{color}
\usepackage{csquotes}
\usepackage{mdwtab}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsthm}
\renewcommand\maketitle{\frame[plain]{\titlepage}\addtocounter{framenumber}{-1}}
\providecommand{\alert}[1]{\textbf{#1}}

\title{Tutorial Machine Learning in Python}
\author{Andreas M\"{u}ller, Hannes Schulz, and Sven Behnke\\[5mm]\includegraphics[width=.2\linewidth]{style/Logo_UBo_h24_4c-crop}}
\date{ICANN 2012}
\begin{document}

\maketitle


\lstset{%
    basicstyle=\small\tt,
    keywordstyle=\color{beamer@bonnblue}\bfseries, % style for keywords
    numbers=none, % where to put the line-numbers
    numberstyle=\tiny, % the size of the fonts that are used for the line-numbers
    showspaces=false, % show spaces adding particular underscores
    showstringspaces=false, % underline spaces within strings
    showtabs=false, % show tabs within strings adding particular underscores
    tabsize=2, % sets default tabsize to 2 spaces
    captionpos=b, % sets the caption-position to bottom
    breaklines=true, % sets automatic line breaking
    breakatwhitespace=false, 
}
\newcommand\fenc{f_{\mathrm{enc}}}
\newcommand\fdec{f_{\mathrm{dec}}}
\newcommand\Wand{\ensuremath{W_{\mathbf{and}}}}
\newcommand\Wor{\ensuremath{W_{\mathbf{or}}}}
\newcommand{\w}[1]{\ensuremath{\mathbf{#1}}}
\newcommand\loss{\ell}

\frame[plain]{\frametitle{Outline}\tableofcontents\addtocounter{framenumber}{-1}}
\section{Introduction}


\begin{frame}
    \frametitle{Machine Learning Overview}
    Before Lunch: Unsupervised Learning
    \begin{itemize}
        \item Slides
            \begin{itemize}
                \item PCA
                    - Slides
                      - have: high-dim noisy data, no way to look at it
                      - Dimensionality Reduction (e.g. for visualization)
                      - Determining relevant axes
                      - Noise removal
                    - interactive:
                      - load data
                      - plot data
                      - do PCA on blobs
                      - plot transformed/backtransformed data
                      - select subset of eigenvectors
                      - plot transformed/backtransformed data
                      - same with some high-dim bio data (TODO: find good data!)
                \item K-Means
                    - interactive:
                      - find blobs on artificial data
                      - color discretization in an image (TODO: bio images (--> Kristian & Baukhage?))
                      - visualize cluster centers in "interesting data" (TODO: data??)
            \end{itemize}
    \end{itemize}

    After Lunch: Supervised Learning
    \begin{itemize}
        \item General
            - Supervised Learning
            - Training, Testing
        \item Linear Regression, 
            - Slides
                - talk about regression coefficients
                - prediction error
                - draw line in 2D
                - (draw plane in 3D)
                - formula for hyperplane
                - formula for the loss
            - interactive
              - use some real-world dataset
                http://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html
              - find w hat by calling linear regression function
              - measure prediction error for withheld subset data
              - plot result (tricky)
              - same using boston housing or diabetes dataset
        \item Classification (mention not only linear?)
            - Logistic Regression
              - Slides
                - have: data, binary categorical variable
                - want: simple (linear, interpretable?) function that distinguishes between classes 
                - how:
                  - draw line in 2D on blobs
                  - (draw plane in 3D) on blobs
                  - formula for hyperplane
                  - minimize error using
                  - formula for the loss
              - interactive
                - some 2D blobs dataset
                - Breast Cancer dataset
                - http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29
            - KNN
              - Slides:
                - have: data, categorical variable
              - interactive
                - start with blobs from k-means
                - Iris dataset
                - Measure prediction error
                - Maybe: Complexity curve visualization (needs a loop)
    \end{itemize}
\end{frame}

\end{document}
