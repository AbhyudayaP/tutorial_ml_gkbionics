{
 "metadata": {
  "name": "5 - k Nearest Neighbors"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "k Nearest Neighbors\n",
      "=====================\n",
      "We create a dataset consisting of a small circle surrounded by a larger circle.\n",
      "\n",
      "First, we will try to fit is using logistic regression, than we will use $k$ Nearest Neighbors.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_circles\n",
      "X, y = make_circles(noise=.1, factor=.5)\n",
      "print \"X.shape:\", X.shape\n",
      "print \"unique labels: \", np.unique(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's plot the data again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.prism()\n",
      "plt.scatter(X[:, 0], X[:, 1], c=y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take the first 50 examples for training and the rest for testing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = X[:50]\n",
      "y_train = y[:50]\n",
      "X_test = X[50:]\n",
      "y_test = y[50:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import logistic regression and fit the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "logreg = LogisticRegression()\n",
      "logreg.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Evaluate the logistic regression as we did before by ploting the decision surface and predictions on the test data.\n",
      "We plot the training data as circles, colored with their true labels.\n",
      "The test data is colored with their prediction and plotted as triangles."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utility import plot_decision_boundary\n",
      "y_pred_test = logreg.predict(X_test)\n",
      "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred_test, marker='^')\n",
      "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
      "plot_decision_boundary(logreg, X)\n",
      "plt.xlim(-1.5, 1.5)\n",
      "plt.ylim(-1.5, 1.5)\n",
      "print \"Accuracy of logistic regression on test set:\", logreg.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That doesn't look as good as before. Notice that all test points on the right of the line are red and all on the left are green. (as expected)\n",
      "\n",
      "Now let us look at how K Nearest Neighbors works here. Let us import the classifier and create an object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "knn = KNeighborsClassifier(n_neighbors=5)    # we specify that this knn should always use 5 neighbors\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn.fit(X_train, y_train)\n",
      "y_pred_test = knn.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.xlim(-1.5, 1.5)\n",
      "plt.ylim(-1.5, 1.5)\n",
      "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred_test, marker='^')\n",
      "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
      "print \"Accuracy of KNN test set:\", knn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This looks much better, which is also reflected by the test set score.\n",
      "\n",
      "We'll leave improving this for later and now have a look at MNIST again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_mldata\n",
      "from sklearn.utils import shuffle\n",
      "mnist = fetch_mldata(\"MNIST original\")\n",
      "X_digits, y_digits = mnist.data, mnist.target\n",
      "X_digits, y_digits = shuffle(X_digits, y_digits)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This time we use all classes, but only a small training set (because KNN usually takes a while).\n",
      "To do model selection, we also create a valdation set to adjust $k$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_digits_train = X_digits[:1000]\n",
      "y_digits_train = y_digits[:1000]\n",
      "X_digits_valid = X_digits[1000:2000]\n",
      "y_digits_valid = y_digits[1000:2000]\n",
      "X_digits_test = X_digits[2000:3000]\n",
      "y_digits_test = y_digits[2000:3000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let us fit the model. That actually just remembers the dataset. Then we will evaluate on the validation set.\n",
      "\n",
      "This time we choose $k=20$.\n",
      "You can find a good value later.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn_digits = KNeighborsClassifier(n_neighbors=20)\n",
      "knn_digits.fit(X_digits_train, y_digits_train)\n",
      "print \"KNN validation accuracy on MNIST digits: \", knn_digits.score(X_digits_valid, y_digits_valid)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After you found a good value of $k$, you can evaluate again on the test set (only do this once to have a meaningful result!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"KNN test accuracy on MNIST digits: \", knn_digits.score(X_digits_test, y_digits_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a better understanding of the classifier, let us take a closer look at some mistake that are done with $k=3$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn_digits = KNeighborsClassifier(n_neighbors=3)\n",
      "knn_digits.fit(X_digits_train, y_digits_train)\n",
      "y_digits_valid_pred = knn_digits.predict(X_digits_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the neighbors of the validation data from the training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neighbors = knn_digits._tree.query(X_digits_valid, k=3)[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not let's look at them. Let's start with an image where it worked. First plot the validation image itself, then three neibhbors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rc(\"image\", cmap=\"binary\")\n",
      "# plot X_digits_valid[0]\n",
      "plt.subplot(1, 4, 1)\n",
      "plt.imshow(X_digits_valid[0].reshape(28, 28))\n",
      "plt.title(\"Query\")\n",
      "# plot three nearest neighbors from the training set\n",
      "for i in [0, 1, 2]:\n",
      "    plt.subplot(1, 4, 2 + i)\n",
      "    plt.title(\"%dth neighbor\" % i)\n",
      "    plt.imshow(X_digits_train[neighbors[0, i]].reshape(28, 28)) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find out where we went wrong on the validation set, so we can have a look."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wrong = np.where(y_digits_valid_pred != y_digits_valid)[0]  # the != part gives a mask, the \"where\" gives us the indices\n",
      "print \"Wrong prediction on the following images: \", wrong\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now take one of these and visualize a neighbor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = wrong[0]\n",
      "\n",
      "# plot X_digits_valid[index]\n",
      "plt.subplot(1, 4, 1)\n",
      "plt.imshow(X_digits_valid[index].reshape(28, 28))\n",
      "plt.title(\"Query\")\n",
      "# plot three nearest neighbors from the training set\n",
      "for i in [0, 1, 2]:\n",
      "    plt.subplot(1, 4, 2 + i)\n",
      "    plt.title(\"%dth neighbor\" % i)\n",
      "    plt.imshow(X_digits_train[neighbors[index, i]].reshape(28, 28)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Playing with the notebook\n",
      "=========================\n",
      "1. Find a good $k$ for the simple circle dataset.\n",
      "2. Find a good $k$ for the MNIST dataset using the valiation set, then test once on the test set. How do the results on the validation set and test set differ?\n",
      "3. How does the performance of KNN change when you change the size of the training set? (If you make it larger than 5000, you might have to wait a bit). Why does it change like this?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}